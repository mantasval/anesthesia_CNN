{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 128\n",
    "N_SAMPLES_PER_EPOCH = 5 * SAMPLING_RATE\n",
    "\n",
    "def get_data_files():\n",
    "    files =  list(Path('./data').glob('*.mat'))\n",
    "    return files\n",
    "\n",
    "def bis_to_groups(bis):\n",
    "    if bis < 40 and bis >= 0:\n",
    "        return '0-40'\n",
    "    elif bis >= 40 and bis < 65:\n",
    "        return '40-65'\n",
    "    elif bis >= 65 and bis < 85:\n",
    "        return '65-85'\n",
    "    elif bis >= 85 and bis <= 100:\n",
    "        return '85-100'\n",
    "\n",
    "def mat_to_df(file):\n",
    "    data = loadmat(file)\n",
    "    eeg_data = data['EEG'].flatten()\n",
    "    bis_data = data['bis'].flatten()\n",
    "    bis_mapped = list(map(bis_to_groups, bis_data[bis_data != -1][:len(eeg_data)//N_SAMPLES_PER_EPOCH]))\n",
    "    eeg_epochs = eeg_data[:len(bis_mapped)*N_SAMPLES_PER_EPOCH].reshape(len(bis_mapped), N_SAMPLES_PER_EPOCH)\n",
    "    df = pd.DataFrame(eeg_epochs)\n",
    "    df['bis'] = bis_mapped\n",
    "    return df\n",
    "\n",
    "def get_all_data():\n",
    "    return pd.concat([mat_to_df(file) for file in get_data_files()])\n",
    "\n",
    "def standardize_data(x_train,x_valid, x_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.concatenate([x_train, x_valid]))\n",
    "    x_train, x_valid, x_test = [scaler.transform(x).reshape(-1, N_SAMPLES_PER_EPOCH, 1) for x in [x_train, x_valid, x_test]]\n",
    "    return x_train, x_valid, x_test\n",
    "\n",
    "def get_train_valid_test_data():\n",
    "    df = get_all_data()\n",
    "    train, validate, test =  np.split(df.sample(frac=1, random_state=42), [int(0.7*len(df)), int(0.85*len(df))])\n",
    "   \n",
    "    x_train, x_valid, x_test = standardize_data(*[df.drop('bis', axis=1).to_numpy() for df in [train, validate, test]])\n",
    "    y_train, y_valid, y_test = [df['bis'].to_numpy() for df in [train, validate, test]]\n",
    "\n",
    "    print(train.shape, validate.shape, test.shape)\n",
    "    print(x_train.shape, x_valid.shape, x_test.shape)\n",
    "    print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "    \n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "def one_hot_encode(y_train, y_valid, y_test):\n",
    "    encoder = LabelEncoder()\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "    y_train = encoder.transform(y_train)\n",
    "    y_valid = encoder.transform(y_valid)\n",
    "    y_train, y_valid, y_test = [keras.utils.to_categorical(y) for y in [y_train, y_valid, y_test]]\n",
    "    return y_train, y_valid, y_test, encoder\n",
    "\n",
    "def save_test_data(x_test, y_test, model_name):\n",
    "    Path('./test_data').mkdir(exist_ok=True)\n",
    "    np.savez(f'./test_data/{model_name}.npz', x_test=x_test, y_test=y_test)\n",
    "\n",
    "def load_test_data(model_name):\n",
    "    loaded_data = np.load(f'./test_data/{model_name}.npz', allow_pickle=True)\n",
    "    x_test_loaded = loaded_data['x_test']\n",
    "    y_test_loaded = loaded_data['y_test']\n",
    "    return x_test_loaded, y_test_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes=4):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(\n",
    "        filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(\n",
    "        filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(\n",
    "        filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                 keras.metrics.AUC(name='auc'),\n",
    "                 keras.metrics.Precision(name='precision'),\n",
    "                 keras.metrics.Recall(name='recall')],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_class_weights(y_train):\n",
    "    y_train_labels = np.argmax(y_train, axis=1)\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_train_labels),\n",
    "        y=y_train_labels\n",
    "    )\n",
    "    class_weights_dict = dict(enumerate(class_weights))\n",
    "    print(\"Class Weights:\", class_weights_dict)\n",
    "    return class_weights_dict\n",
    "\n",
    "\n",
    "def fit_model(model, model_name,  x_train, y_train, x_valid, y_valid, epochs=10, balance_classes=False):\n",
    "    class_weights_dict = get_class_weights(y_train) if balance_classes else None\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f\"./models/{model_name}.keras\", save_best_only=True, monitor=\"val_loss\"\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=10, min_lr=0.0001\n",
    "        ),\n",
    "        keras.callbacks.CSVLogger(\n",
    "            f\"./training_csv/{model_name}_training.csv\", separator=\",\", append=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights_dict\n",
    "    )\n",
    "\n",
    "def evaluate_model(model, model_name, x_test, y_test):\n",
    "    results = model.evaluate(x_test, y_test, verbose=2, return_dict=True)\n",
    "    df = pd.DataFrame([results])\n",
    "    df.to_csv(f\"./evals/{model_name}_eval.csv\")\n",
    "\n",
    "def plot_confusion_matrix(model, model_name, X_test, y_test, le):\n",
    "    y_predicted = le.inverse_transform(np.argmax(model.predict(X_test), axis=1))\n",
    "    y_true = le.inverse_transform(np.argmax(y_test, axis=1))\n",
    "    report = classification_report(y_true, y_predicted, output_dict=True)\n",
    "    report_normal = classification_report(y_true, y_predicted)\n",
    "    print(report_normal)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(f\"./CMs/{model_name}_CM.csv\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_predicted, labels=le.classes_)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d',cmap = 'Blues',  xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(f'./CMs/{model_name}_CM.png')\n",
    "    plt.show()\n",
    "\n",
    "def all_vs_all_classification(epochs=100, balance_classes=False):\n",
    "    num_classes = 4\n",
    "    balance = \"balanced\" if balance_classes else \"unbalanced\"\n",
    "    model_name = f\"all_VS_all_z_norm_{balance}_{epochs}e\"\n",
    "    x_train, x_valid, x_test, y_train_og, y_valid_og, y_test_og = get_train_valid_test_data()\n",
    "    save_test_data(x_test, y_test_og, model_name)\n",
    "    y_train, y_valid, y_test, encoder = one_hot_encode(y_train_og, y_valid_og, y_test_og)\n",
    "    \n",
    "    model = compile_model(make_model(x_train.shape[1:], num_classes))\n",
    "    fit_model(model, model_name, x_train, y_train, x_valid, y_valid, epochs=epochs, balance_classes=balance_classes)\n",
    "\n",
    "    model = keras.models.load_model(f\"./models/{model_name}.keras\")\n",
    "    evaluate_model(model, model_name, x_test, y_test)\n",
    "    plot_confusion_matrix(model, model_name, x_test, y_test, encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vs_all_classification(epochs=100, balance_classes=False)\n",
    "all_vs_all_classification(epochs=100, balance_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    input_shape = (640, 1) \n",
    "    num_classes = 4     \n",
    "\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(hp.Int(\"num_conv_layers\", min_value=1, max_value=9)): \n",
    "        x = keras.layers.Conv1D(\n",
    "            filters=hp.Int(f\"filters_{i}\", min_value=16, max_value=128, step=16),\n",
    "            kernel_size=hp.Int(f\"kernel_size_{i}\", min_value=1, max_value=7),\n",
    "            padding=\"same\"\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.ReLU()(x)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    output_layer = keras.layers.Dense(\n",
    "        num_classes, activation=\"softmax\"\n",
    "    )(x)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"categorical_crossentropy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_hypertuning():\n",
    "    x_train, x_valid, x_test, y_train_og, y_valid_og, y_test_og = get_train_valid_test_data()\n",
    "    y_train, y_valid, y_test, encoder = one_hot_encode(y_train_og, y_valid_og, y_test_og)\n",
    "    x_val = np.concatenate([x_valid, x_test])\n",
    "    y_val = np.concatenate([y_valid, y_test])\n",
    "\n",
    "    class_weights = get_class_weights(y_train)\n",
    "    tuner = kt.Hyperband(\n",
    "        build_model,\n",
    "        objective=\"val_categorical_crossentropy\",\n",
    "        max_epochs=100,      \n",
    "        factor=3,           \n",
    "        directory=f\"hyperparameter_tuning_z_norm_unbalanced\",   \n",
    "        project_name=\"cnn_tuning_with_val_loss\"\n",
    "        )\n",
    "\n",
    "    tuner.search(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weights\n",
    "        )\n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hypertuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model():\n",
    "    tuner = kt.Hyperband(\n",
    "        build_model,\n",
    "        objective=\"val_categorical_crossentropy\",\n",
    "        directory=f\"hyperparameter_tuning_z_norm_unbalanced\",   \n",
    "        project_name=\"cnn_tuning_with_val_loss\"\n",
    "        )\n",
    "    model = tuner.hypermodel.build(tuner.get_best_hyperparameters(num_trials=2)[-1])\n",
    "    return model\n",
    "\n",
    "def train_best_model(balanced=True, epochs=100):\n",
    "    balance = \"balanced\" if balanced else \"unbalanced\"\n",
    "    best_model_name = f\"best_model_z_norm_{balance}_{epochs}e\"\n",
    "    x_train, x_valid, x_test, y_train_og, y_valid_og, y_test_og = get_train_valid_test_data()\n",
    "    y_train, y_valid, y_test, encoder = one_hot_encode(y_train_og, y_valid_og, y_test_og)\n",
    "    save_test_data(x_test, y_test_og, best_model_name)\n",
    "\n",
    "    best_model = get_best_model()\n",
    "    best_model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                 keras.metrics.AUC(name='auc'),\n",
    "                 keras.metrics.Precision(name='precision'),\n",
    "                 keras.metrics.Recall(name='recall')],\n",
    "    )\n",
    "    fit_model(best_model, best_model_name, x_train, y_train, x_valid, y_valid, epochs, balance_classes=balanced)\n",
    "    evaluate_model(best_model, best_model_name, x_test, y_test)\n",
    "    plot_confusion_matrix(best_model, best_model_name, x_test, y_test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_best_model(balanced=False, epochs=100)\n",
    "train_best_model(balanced=True, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
